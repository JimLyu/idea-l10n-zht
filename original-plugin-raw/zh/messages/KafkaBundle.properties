action.Kafka.AddToFavoriteAction.text=添加到收藏夹
action.Kafka.DeleteSchemaAction.description=删除架构注册表主题
action.Kafka.DeleteSchemaAction.text=删除架构
action.Kafka.GlobalCreateKafkaConnection.text=创建 Kafka 连接
action.Kafka.RemoveFromFavoriteAction.text=从收藏夹中移除
action.clear.output=清除输出
action.clear.partition.multi.message=是否删除分区 {0} 中的所有记录? 此操作无法撤消。
action.clear.partition.single.message=是否删除分区 "{0}" 中的所有记录? 此操作无法撤消。
action.clear.partition.title=清除分区
action.clear.topic.single.message=是否删除主题 "{0}" 中的所有记录? 此操作无法撤消。
action.consume.start.title=开始使用
action.consume.stop.title=停止使用
action.create.new.version=编辑主题
action.delete.consumer.group.single.message=Delete consumer group "{0}"? This action cannot be undone.
action.delete.topic.multi.message=是否删除 {0} 个主题?
action.delete.topic.single.message=是否删除主题“{0}”?
action.delete.topic.title=删除
action.delete.version.text=删除版本
action.kafka.ClearPartition.text=清除分区
action.kafka.ClearTopicAction.text=清除主题
action.kafka.CloneSchemaAction.text=克隆架构
action.kafka.CreateSchemaAction.text=创建架构
action.kafka.CreateTopicAction.text=创建主题
action.kafka.DeleteConsumerGroupAction.text=Delete Consumer Group
action.kafka.DeleteTopicAction.text=删除主题
action.kafka.ResetOffsetsAction.text=Reset Offset
action.kafka.create.consumer.text=创建 Kafka 使用者
action.kafka.create.producer.text=创建 Kafka 生产者
action.open.details=打开详细信息
action.produce.stop=停止生产
action.remove.preset=移除预设
action.remove.schema.confirm.dialog.msg.permanent=架构 "{0}" 已被软删除。是否将其永久删除?
action.remove.schema.confirm.dialog.msg.soft=是否删除架构 "{0}"?
action.remove.schema.confirm.dialog.title=删除
action.remove.version.confirm.dialog.msg=是否删除主题“{1}”的版本 {0}?
action.remove.version.confirm.dialog.option=永久删除
action.save.preset=保存预设
action.show.favorite.schemas=显示最喜欢的架构
action.table.stats=表统计信息
all.topics=所有主题
border.title.ssl.settings=SSL 设置
column.name.default=默认
column.name.documentation=文档
column.name.name=名称
column.name.required=必要
column.name.type=类型
config.name.default=Kafka
connection.admin.is.not.initialized=Kafka 管理客户端未初始化
connection.check.port.success.but.next.error=URL 可访问，但 Kafka 无法连接。请检查是否设置了正确的身份验证机制
connection.error.tunnel.for.sinlgle.broker=SSH tunnel can be created just for a single broker url
connection.is.not.found.in.config=在连接属性中找不到 {0}
connection.kafka.registry.is.not.available=Kafka 注册表不可用
consume.from.topic=从主题使用
consumer.details.empty=For details, select row in data table
consumer.error.topic.empty=未选择主题
consumer.error.topic.empty.title=使用者错误
consumer.filter.type.contains=包含
consumer.filter.type.none=无
consumer.filter.type.notContains=不包含
consumer.filter.type.regexp=RegExp
consumer.group.dialog.change.offset.datetime.label=日期时间:
consumer.group.dialog.change.offset.offset.label=偏移:
consumer.group.dialog.change.offset.strategy.label=Strategy:
consumer.group.lag=Lag
consumer.last.update.label.canceled=已取消
consumer.last.update.label.comment={0} updated
consumer.last.update.label.error=错误
consumer.last.update.label.initializing=正在执行...
consumer.limit.type.date=日期
consumer.limit.type.none=无
consumer.limit.type.partitionMaxSize=分区最大大小
consumer.limit.type.partitionRecords=分区记录号
consumer.limit.type.topicMaxSize=主题最大大小
consumer.limit.type.topicRecords=主题记录号
consumer.partition.not.found=找不到主题 {0} 的所选分区。
consumer.preset.filter=筛选器: {0}
consumer.preset.header.key=标头键: {0}
consumer.preset.header.value=标头值: {0}
consumer.preset.key=键: {0}
consumer.preset.limit=限制 {0} {1}
consumer.preset.no.topic=无主题
consumer.preset.topic=主题: {0}
consumer.preset.value=值: {0}
consumer.producer.format.type=类型:
consumer.producer.key.group=键
consumer.producer.value.group=值
consumer.record.key=键:
consumer.record.keysize=键大小:
consumer.record.offset=偏移:
consumer.record.partition=分区:
consumer.record.timestamp=时间戳:
consumer.record.topic=主题:
consumer.record.value=值:
consumer.record.valuesize=值大小:
consumer.records.limit=使用者记录限制
consumer.records.limit.descr=当记录数达到限制时，将清除客户端上的旧记录。<br>负数，'0' 或空值表示没有限制。
consumer.start.type.beginning=从开头
consumer.start.type.consumerGroup=使用者组
consumer.start.type.lastHour=过去 1 小时
consumer.start.type.latestOffsetMinusX=最新偏移量减去 X
consumer.start.type.now=Latests
consumer.start.type.offset=Offset from beginning
consumer.start.type.specificDate=具体日期
consumer.start.type.today=今天
consumer.start.type.yesterday=昨天
consumer.table.awaiting=正在等待数据
create.topic.leave.empty.for.default=使用默认值
custom.shema.source.type.file=文件
custom.shema.source.type.implicit=显式
data.BdtTopicPartition.endOffset=End Offset
data.BdtTopicPartition.inSyncReplicasCount=In Sync Replicas Count
data.BdtTopicPartition.leader=Leader
data.BdtTopicPartition.partitionId=Partition ID
data.BdtTopicPartition.replicas=Replicas
data.BdtTopicPartition.startOffset=Start Offset
data.BdtTopicPartition.topic=主题
data.ConsumerGroupPresentable.consumerGroup=Consumer Group
data.ConsumerGroupPresentable.state=状态
data.KafkaSchemaInfo.compatibility=兼容性
data.KafkaSchemaInfo.description=描述
data.KafkaSchemaInfo.isSoftDeleted=Is Soft Deleted
data.KafkaSchemaInfo.name=名称
data.KafkaSchemaInfo.schemaStatus=Schema Status
data.KafkaSchemaInfo.type=按类型分组
data.KafkaSchemaInfo.updatedTime=Updated Time
data.KafkaSchemaInfo.version=版本
data.SchemaRegistryFieldsInfo.default=默认
data.SchemaRegistryFieldsInfo.description=描述
data.SchemaRegistryFieldsInfo.id=ID
data.SchemaRegistryFieldsInfo.name=名称
data.SchemaRegistryFieldsInfo.required=必要
data.SchemaRegistryFieldsInfo.type=按类型分组
data.TopicConfig.defaultValue=默认值
data.TopicConfig.name=名称
data.TopicConfig.value=值
data.TopicPresentable.inSyncReplicas=In Sync Replicas
data.TopicPresentable.messageCount=Message Count
data.TopicPresentable.name=名称
data.TopicPresentable.noLeaders=No Leaders
data.TopicPresentable.partitions=分区
data.TopicPresentable.replicas=Replicas
data.TopicPresentable.replicationFactor=Replication Factor
data.TopicPresentable.underReplicatedPartitions=Under Replicated Partitions
dialog.create.topic.name=名称:
dialog.create.topic.num.partition=分区数量:
dialog.create.topic.replication.factor=复制系数:
diff.dialog.button.update=更新
diff.dialog.title=架构之间的区别
error.configuration.glue.is.not.setup=未配置 Glue 架构注册表
error.confluent.registry.url.empty=提供 Confluent 注册表 URL
error.output.row.key=错误
error.producer.title=Kafka 生产者
error.schema.infinite.recursion=由于递归引用，无法进行验证
error.schema.is.not.chosen=选择一个架构。
error.start.consumer=使用者错误
error.topic.is.not.chosen=选择主题.
exportable.BdtKafkaConfigTemplate.presentable.name=Big Data Tools Kafka 使用者/生产者设置
exportable.KafkaSettings.presentable.name=Big Data Tools Kafka 工具窗口设置
field.type.base64=字节(Base64)
field.type.custom.avro=Avro (自定义)
field.type.custom.protobuf=Protobuf (自定义)
field.type.double=Double
field.type.float=Float
field.type.integer=整数
field.type.json=JSON
field.type.long=Long
field.type.null=无
field.type.registry=架构注册表
field.type.string=String
field.viewer.type.auto=自动
field.viewer.type.base64=Base64
field.viewer.type.json=JSON
field.viewer.type.text=文本
generate.random.data=生成随机数据
gutter.action.observe.messages.in.topic=观测主题中的消息
gutter.action.opens.kafka.consumer.ui.description=打开 Kafka 使用者 UI
gutter.action.opens.kafka.producer.ui.description=打开 Kafka 生产者 UI
gutter.action.send.messages.to.topic=向主题发送消息
gutter.action.setup.connection=设置与 Kafka 的连接
gutter.action.setup.connection.description=在 IDE 中创建与 Kafka 集群的连接
gutter.name.kafka.configuration.in.spring.boot=Spring Boot 中的 Kafka 配置
kafka.auth.aws_iam=AWS IAM
kafka.auth.basic=基本身份验证
kafka.auth.bearer=持有者
kafka.auth.enable.server.host.name.indetification=验证服务器主机名
kafka.auth.method.label=身份验证:
kafka.auth.none=无
kafka.auth.sasl.use.ssl=启用 SSL
kafka.auth.sasls=SASL
kafka.auth.ssl=SSL
kafka.auth.type.kerberos=Kerberos
kafka.auth.type.plain=纯
kafka.auth.type.scram256=SCRAM-SHA-256
kafka.auth.type.scram512=SCRAM-SHA-512
kafka.broker.group.title=Kafka 代理
kafka.key.password=密钥密码:
kafka.keystore.location=密钥库位置:
kafka.keystore.password=密钥库密码:
kafka.password=密码:
kafka.producer.action.produce.title=生成
kafka.property.source.field=隐式
kafka.property.source.file=来自文件
kafka.property.source.label=属性源:
kafka.registry.proxy.label=代理 URL:
kafka.registry.use.broker.ssl.settings.checkbox=使用代理 SSL 设置
kafka.registry.use.proxy=使用代理
kafka.sasl.mechanism=SASL 机制:
kafka.ssl.use.keystore=使用 Keystore 客户端身份验证
kafka.token=令牌:
kafka.truststore.location=信任库位置:
kafka.truststore.location.dialog.title=选择信任库位置
kafka.truststore.password=信任库密码:
kafka.username=用户名:
kafka.validation.error.label=验证错误
label.filter.head.key=标头键:
label.filter.head.value=标头值:
label.filter.key=键:
label.filter.limit=限制
label.filter.value=值:
label.key.type=密钥类型:
label.value.type=值类型:
link.label.compare=比较…
message.title=Kafka
notification.generate.failed.text=无法为给定架构生成随机数据
notification.generate.failed.title=生成失败
notification.group.kafka=Kafka 插件
open.settings.action.text=设置
output.column.duration=持续时间
output.column.key=键
output.column.offset=偏移
output.column.partition=分区
output.column.timestamp=时间戳
output.column.value=值
produce.to.topic=生产到主题
producer.asks=ACK:
producer.compression=压缩:
producer.config.link.load.file=下载文件...
producer.config.link.upload.file=上传文件...
producer.config.random.generation.enabled=Random generation enabled
producer.error.topic.empty=未选择主题
producer.field.double.invalid="{0}" is not a valid double value
producer.field.float.invalid="{0}" is not a valid float value
producer.field.int.invalid="{0}" is not a valid integer value
producer.field.long.invalid="{0}" is not a valid long value
producer.flow.generate.random.key=生成随机密钥
producer.flow.generate.random.value=生成随机值
producer.flow.interval=间隔(毫秒):
producer.flow.mode.auto=自动
producer.flow.mode.label=模式:
producer.flow.mode.manual=手动
producer.flow.records.count=一次记录数:
producer.flow.stop.conditions.count=生成的记录:
producer.flow.stop.conditions.elapsed.time=经过时间(毫秒):
producer.flow.stop.conditions.title=停止条件
producer.forcePartition=分区:
producer.forcePartition.emptytext=所有
producer.group.flow=Flow
producer.idempotence.comment=如果启用，ACK 将为“全部”
producer.idempotence.label=幂等性
producer.json.value.comment=以 JSON 格式提供与架构对应的有效负载。
producer.key=键:
producer.preset.apply=将预设应用到设置
producer.preset.key=键 [{0}]: {1}
producer.preset.no.key=无键
producer.preset.no.topic=无主题
producer.preset.no.value=无值
producer.preset.none=无
producer.preset.topic=主题: {0}
producer.preset.value=值 [{0}]: {1}
producer.title.headers=标头
producer.title.options=选项
producer.topics=主题:
producer.value=值:
producer.wrong.partition=主题 {1} 的错误分区 {0}
property.file.is.not.found=找不到 Kafka 属性文件 {0}
record.info.headers=标头
record.info.metadata=元数据
registry.add.schema.dialog.title=Add Schema
registry.format.avro=Avro
registry.format.json=JSON
registry.format.protobuf=Protobuf
registry.format.topic.record=主题 记录名称
registry.format.unknown=未知
registry.info.dialog.title=方案“{0}”
registry.key=键
registry.strategy.custom.subject=自定义名称
registry.strategy.record=记录名称
registry.strategy.topic=主题名称
registry.subject.combobox.default.name=选择注册表架构
registry.value=值
schema.info.arn=ARN:
schema.info.compability=兼容性模式:
schema.info.description=描述:
schema.info.format=数据格式:
schema.info.last.updated=上次更新:
schema.info.name=名称:
schema.info.registry=注册表:
schema.info.version=最新版本:
schema.invalid.text=Cannot validate {0}, please revise the schema.
schema.invalid.title=Invalid Schema
schema.name.must.be.not.blank=输入架构名称
schema.name.must.be.not.end.with.slash=The schema name cannot end with /
schema.registry.add.schema.dialog.field.computed.name=Computed name:
schema.registry.add.schema.dialog.field.custom.name=Custom name:
schema.registry.add.schema.dialog.field.format=格式:
schema.registry.add.schema.dialog.field.key.value=名称后缀:
schema.registry.add.schema.dialog.field.record=Record name:
schema.registry.add.schema.dialog.field.schema.name=架构名称:
schema.registry.add.schema.dialog.field.strategy=Strategy:
schema.registry.add.schema.dialog.field.topic=主题:
schema.registry.type.label=类型
schema.type.confluent=Confluent
schema.type.glue=Glue
schema.type.none=无
schema.version.is.not.found=未选择
schema.view.type.schema=原始视图
schema.view.type.structure=树视图
schemas.empty.text=定义架构以强制数据兼容性。
schemas.empty.text.create.link=创建架构
schemas.empty.text.filter=没有与筛选器匹配的架构
settings.advanced=高级设置
settings.broker.type.cloud=云
settings.cloud.provider=提供程序:
settings.cloud.setup.title=如何连接
settings.cloud.type.confluent=Confluent
settings.cloud.type.msk=AWS MSK
settings.confluent.conf.comment=将此字段用于 Kafka 代理和架构注册表属性
settings.confluent.configuration=配置:
settings.confluent.setup.desc=<ol><li>打开<b>https://confluent.cloud/home</b>。</li><li>转到<b>环境 > 集群 > 客户端 > Java</b>。</b>。 li><li>提供 API 密钥或生成新密钥。</li><li>复制属性块并将其粘贴到“配置”字段中。</li></ol>
settings.consumer.group.label=使用者组:
settings.consumer.offset.tab=Consumer Offset
settings.consumers.tab=使用者组
settings.filter=筛选器:
settings.filters.from=起点:
settings.filters.from.not.available.with.consumer.group=Offsets is defined by consumer group
settings.filters.limit=限制:
settings.format.registry.schema=模式:
settings.glue.registry.name=注册表名称:
settings.glue.registry.title=选择 Glue 注册表
settings.group.name=Kafka
settings.label.topics=主题:
settings.msk.setup.desc=<ol><li>登录您的 AWS 帐户并选择您的 MSK 集群。</li><li>点击<b>查看客户端信息</b>并复制<b>公共端点</b>的内容。</li><li>将这些内容粘贴到 IDE 中 Kafka 连接的<b>引导服务器</b>字段。</li></ol>
settings.partitions=分区:
settings.partitions.not.available.if.consumer.group.setup.comment=Cannot use partition filter with consumer group
settings.payload.row.label=有效负载:
settings.properties=高级属性:
settings.properties.file=属性文件:
settings.properties.file.browse=Kafka 属性文件
settings.property.source=配置源:
settings.property.source.file=属性
settings.registry.tab=架构注册表
settings.registry.title=架构注册表(可选)
settings.registry.url=URL:
settings.registry.url.hint=http://localhost:8081
settings.title.other=其他
settings.title.partitions=分区
settings.title.range.filters=范围和筛选器
settings.topics.tab=主题
settings.url=引导服务器:
settings.url.must.be.non.empty.hint=引导服务器不得为空
settings.url.text.empty=server1,server2
settings.url.text.hint=使用 "," 分隔符指定代理列表(server1,server2)
show.edit.schema.diff.new.name=新架构
show.edit.schema.diff.prev.name=最新版本:
show.edit.schema.diff.title=更新主题: {0}
show.edit.schema.diff.version=版本 {0}:
show.favorite.topic=显示最喜欢的主题
show.full.topic.config=显示完整配置
show.full.topic.config.hint=显示完整配置
show.internal.topic=显示内部主题
show.schema.info=显示架构
ssh.tunnel.enable.notification=SSH 隧道仅用于与您在 Bootstrap 服务器中指定的节点的初始直接连接。要连接到 Kafka 集群中的其他代理，请确保可以从您当前的计算机(客户端)访问它们。
table.stats.count=记录:
table.stats.count.per.sec=记录数/秒:
table.stats.count.updates=更新:
table.stats.count.updates.per.sec=更新数/秒:
table.stats.elapsed=用时:
table.stats.size=记录大小:
task.change.offset=Change offset
text.pasting.json.or.csv.available=在这里，您可以粘贴 CSV 和 JSON
toggle.data=数据
toggle.details=详细信息
toggle.presets=预设
toggle.settings=设置
toolwindow.title=Kafka
topic.not.found=找不到主题 {0}
topic.schema.empty.text=设置消息 {0} 架构以强制执行数据兼容性。
topic.schema.empty.text.create.link=设置架构
topic.schema.view.type.key=键
topic.schema.view.type.topic=主题
topic.schema.view.type.value=值
topic.tab.configs=配置
topic.tab.partitions=分区
topic.tab.schema=模式
topic.tab.schema.key=密钥架构
topic.tab.schema.value=值架构
topics.0.partitions.1.urp.2.no.leader.3=主题: {0}  分区: {1}  URP: {2}  无负责人: {3}
topics.empty.text=未找到任何主题
topics.empty.text.filter=没有与筛选器匹配的主题
topics.empty.text.filter.additional=清除筛选器
topics.text.create.link=创建主题
update.dialog.title=更新架构