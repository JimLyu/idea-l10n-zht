group.names.hdfs.data=HDFS 问题

# Connection settings
client.is.not.inited=客户端未初始化

s3.operations.timeout.hint=远程服务器上的操作超时(以秒为单位)

settings.s3.selection.endpoint=与 S3 兼容的存储
settings.s3.custom.endpoint=端点:
settings.s3.custom.region=区域:
settings.s3.custom.region.hint=需要时使用
settings.s3.region=区域:
settings.config.path=配置路径:
settings.custom.roots=根:
settings.bucket.filter=存储桶筛选器:
settings.bucket.filter.type=筛选器类型:
settings.s3.access.key=访问密钥:
settings.s3.secret.key=密钥:
settings.s3.profile.use.custom.path=使用自定义配置
settings.s3.bucket.filter.by.region=仅限所选区域中的存储桶
settings.s3.profile.name=配置文件名称:
settings.s3.profile.credentials.path=凭据路径:
settings.s3.profile.config.path=配置路径:
settings.s3.auth.type=身份验证:
settings.azure.auth.type=身份验证:
settings.azure.endpoint=端点:
settings.azure.username=用户名:
settings.azure.password=密码:
settings.azure.sas.token=SAS 令牌:
settings.azure.connection.string=连接字符串:
settings.azure.user.key=密钥:
settings.azure.container=容器:
settings.hdfs.auth.type=身份验证:
settings.hdfs.url=集群 URI:
settings.minio.endpoint=端点:
setup.video.tutor=连接设置教程视频
settings.undefined.path=<未初始化>

# Connection group names
group.name.hdfs.java=HDFS
group.name.gcs=Google Cloud Storage
group.name.azure=Azure


# GCS settings
gcs.project.id=项目 ID:
gcs.project.id.emptyText=可选的覆盖项目 ID
gcs.project.id.hint=显示特殊项目 ID 的存储桶
gcs.json.location.emptyText=云存储 JSON 位置
gcs.buckets.source=存储桶源:
gcs.custom.url=自定义主机:
gcs.public.hint=为公共存储桶留空
gcs.connection.browse.title=选择凭据 JSON
gcs.connection.error.file.not.exists=文件不存在
gcs.connection.error.cred.file.not.selected=必须为帐号选择凭据文件
gcs.connection.error.bucket.validation1=存储桶名称必须包含 3-63 个字符。包含点的名称最多可包含 222 个字符，但每个以点分隔的组件不得超过 63 个字符。
gcs.connection.error.bucket.validation2=名称只能包含小写字母、数字、破折号(-)、下划线(_)和点(.)。
gcs.connection.error.bucket.validation3=存储桶名称必须以数字或字母开头和结尾。
gcs.connection.error.bucket.validation4=存储桶名称不能表示为用点分隔的十进制形式的 IP 地址(例如 192.168.5.4)。
gcs.connection.error.bucket.validation5=存储桶名称不能以“goog”前缀开头。
gcs.connection.error.bucket.validation6=存储桶名称不能包含“google”或相近的错误拼写，例如“g00gle”。

# HDFS java settings
hdfs.java.driver.home.path=驱动程序主路径:
hdfs.java.config.source=配置源:
hdfs.config.path.title=Java API 配置路径
hdfs.config.path.not.empty=配置路径不应为空
hdfs.config.path.does.not.exist=指定的目录不存在
hdfs.config.path.should.be.directory=配置路径应该指向一个目录
hdfs.config.path.no.xmls.found=指定的目录不包含任何 XML 文件

# S3 settings
s3.auth.type=身份验证类型:
s3.proxy.preemptiveBasicProxyAuth=先行性基本代理身份验证
s3.proxy.preemptiveBasicProxyAuth.hint=是否使用基本身份验证对代理服务器进行先行性身份验证
s3.proxy.disableSocketProxy=禁用套接字代理
s3.proxy.disableSocketProxy.hint=设置是否在套接字级别禁用代理。
s3.proxy.nonProxyHosts=非代理主机:
s3.proxy.nonProxyHosts.hint=可选择指定无需通过代理即可访问的主机。
s3.proxy.ntlm=NTLM 代理支持
s3.proxy.workstation=代理工作站:
s3.proxy.workstation.hint=用于配置 NTLM 代理支持的可选 Windows 工作站名称。
s3.proxy.domain=代理域:
s3.proxy.domain.hint=用于配置 NTLM 代理支持的可选 Windows 域名。
s3.empty.directories.not.allowed=不允许创建空目录

# SFTP settings
group.name.s3=AWS S3
group.name.dospaces=DigitalOcean 空间
group.name.linode=Linode
group.name.minio=MinIO

#HDFS error messages
copy.failed=从 {0} 复制到 {1} 失败。
move.failed=从 {0} 移动到 {1} 失败。
hdfs.ssh.tunnel.ssh.operation.not.supported=不支持通过 SSH 隧道进行操作。
ssh.additional.label=(仅限 NameNode 操作)
ssh.additional.info=SSH 隧道<b>仅适用于名称节点的操作</b>: 列出文件，获取元信息。<br><br>
azure.rename.text2.indicator.deleting={0}: 正在删除 {1}
connection.error.root.path.must.be.non.empty=根路径必须为非空
hdfs.field.root.path=根路径
hdfs.no.xmls.in.directory=配置根中没有 XML 文件
hdfs.is.not.inited=Hdfs 连接未初始化
hdfs.root.folder.does.not.exist=根文件夹 {0} 不存在
notification.title.error.while.reading.orc=读取 ORC 时出错
notification.content.orc.file.looks.invalid.we.can.t.open.it.if.you.believe.that.s.wrong.please.create.issue.at.https.youtrack.jetbrains.com.issues.bdide=ORC 文件看起来无效，且无法打开。如果您知道该文件有效，请在 https://youtrack.jetbrains.com/issues/BDIDE 创建问题
avro.file.is.broken.length.zero=文件 {0} 已损坏。长度: 0
gcs.progress.details.deleting=正在删除 {0}
cannot.open.read.stream.null.blob=无法打开 null blob {0} 的读取流
s3.connection.error.ssh.without.endpoint=要使用 SSH 隧道，请为驱动程序指定一个端点
group.name.emr=AWS EMR
emr.is.not.inited=EMR 客户端未初始化
emr.toolwindow.title=AWS EMR

emr.cluster.terminate.cluster.message=是否要终止集群 {0}?
emr.cluster.terminate.cluster.title=集群正在终止
controller.cluster.steps.error=集群步骤更新错误
emr.cluster.filter=按状态筛选
emr.cluster.filter.limit=限制
emr.filter.text=筛选器:
cannot.find.linode.region=找不到 {0} 的区域
rfs.create.bucket.message=创建存储桶
emr.spark.submit.editor.name=名称:
emr.spark.submit.editor.args=实参:
emr.spark.submit.editor.jar.loc=JAR 位置:
emr.spark.submit=EMR Spark-submit

s3.multibucket.update.text=S3 兼容存储支持多存储桶。您可以在连接设置中配置它们。
s3.multibucket.update.title=BigDataTools 的新 S3 功能
s3.multibucket.open.settings=打开设置
s3.bucket.text.empty=所有存储桶均可见
s3.bucket.text.hint=如果此字段为空，则所有存储桶都将可见<br>输入存储桶名称并选择筛选器类型“匹配”以处理单个存储桶<br>使用“,”分隔存储桶(bucket1, bucket2)
emr.error=AWS EMR 异常

# Auth type
auth.type.default=默认凭据提供程序链
auth.type.keypair=显式访问密钥和密钥
auth.type.namedprofile=已命名的配置文件
auth.type.credentialsfile=来自凭据文件的配置文件
connection.error.hadoop.home.is.not.defined.full=HADOOP_HOME 未定义。在 Windows 上，您应该定义 HADOOP_HOME 环境变量或 Java 属性 hadoop.home.dir。请参阅 <a href=\"https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\">Hadoop Wiki</a>，了解更多详细信息。
connection.error.hadoop.no.native.drivers.full=无法在 HADOOP_HOME 中找到原生驱动程序。请参阅 <a href=\"https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\">Hadoop Wiki</a>，了解更多详细信息。

emr.step.mapper.choose=选择 Mapper
emr.step.reducer.choose=选择 Reducer
emr.step.s3.input.choose=选择 S3 输入
emr.step.s3.output.choose=选择 S3 输出

emr.step.script.choose=选择 S3 脚本位置

emr.label.choose.key.file.for.aws.pair=为 AWS {0} 对选择密钥文件
emr.dialog.title.select.key.ssh.file=选择 SSH 密钥文件
controller.cluster.instances.error=更新集群实例错误

aws.cluster.info.action.open.subnet=打开子网
aws.cluster.info.action.open.master.security.group=主安全组
aws.cluster.info.action.open.slave.security.group=核心和任务安全组

emr.step.details=显示步骤详细信息
emr.cluster.info.details=显示为 JSON

emr.remove.linked.connections.title=EMR 连接
emr.remove.linked.connections.desc=是否要删除为 EMR 创建的连接?
emr.remove.linked.connections.action=移除连接
emr.keys.settings.table.empty=未提供 SSH 密钥
emr.keys.settings.column.key.name=键名
emr.keys.settings.column.key.path=路径
emr.keys.settings.label=SSH 密钥:
emr.keys.settings.link=管理用于连接到 EMR 集群的 SSH 密钥…
emr.key.storage.dialog.title=EMR SSH 密钥库

group.name.yandex=Yandex 对象存储

# DigitalOceanRegions
do.region.nyc3=美国纽约市
do.region.ams3=荷兰阿姆斯特丹
do.region.sfo=美国旧金山
do.region.sgp1=新加坡
do.region.fra1=德国法兰克福

# LinodeRegions
linode.region.us-east=美国东部(美国纽瓦克)
linode.region.us-southeast=美国东南部(美国亚特兰大)
linode.region.eu-central=欧盟中部(德国法兰克福)
linode.region.ap-south=亚太南部(新加坡)

group.name.alibaba=Alibaba OSS

settings.alibaba.region=区域:
alibaba.bucket.create.dialog.hierarchical.field=分层命名空间
alibaba.task.delete.directory.text2=已删除 {0} 个对象
alibaba.task.delete.directory.text=正在删除目录 {0}
alibaba.task.delete.file.text=正在删除文件 {0}
alibaba.task.delete.bucket.text=正在删除存储桶 {0}

# AlibabaRegions
alibaba.region.oss-cn-hangzhou=中国(杭州)
alibaba.region.oss-cn-shanghai=中国(上海)
alibaba.region.oss-cn-qingdao=中国(青岛)
alibaba.region.oss-cn-beijing=中国(北京)
alibaba.region.oss-cn-zhangjiakou=中国(张家口)
alibaba.region.oss-cn-huhehaote=中国(呼和浩特)
alibaba.region.oss-cn-wulanchabu=中国(乌兰察布)
alibaba.region.oss-cn-shenzhen=中国(深圳)
alibaba.region.oss-cn-heyuan=中国(河源)
alibaba.region.oss-cn-guangzhou=中国(广州)
alibaba.region.oss-cn-chengdu=中国(成都)
alibaba.region.oss-cn-hongkong=中国(香港)
alibaba.region.oss-us-west-1=美国(硅谷)
alibaba.region.oss-us-east-1=美国(弗吉尼亚州)
alibaba.region.oss-ap-southeast-1=澳大利亚(悉尼) 1
alibaba.region.oss-ap-southeast-2=澳大利亚(悉尼) 2
alibaba.region.oss-ap-southeast-3=马来西亚(吉隆坡)
alibaba.region.oss-ap-southeast-5=印度尼西亚(雅加达)
alibaba.region.oss-ap-northeast-1=日本(东京)
alibaba.region.oss-ap-south-1=印度(孟买)
alibaba.region.oss-eu-central-1=德国(法兰克福)
alibaba.region.oss-eu-west-1=英国(伦敦)
alibaba.region.oss-me-east-1=阿联酋(迪拜)
alibaba.region.oss-ap-southeast-6=菲律宾(马尼拉)
wrong.region=找不到区域“{0}”

alibaba.settings.credentials.file=Alibaba 凭据文件
dialog.title.s3.profiles.credentials.file=凭据文件
dialog.title.s3.profiles.config.file=配置文件
open.credentials=打开凭据
s3.column.name.storage.class=存储类
s3.column.name.metadata=元数据
s3.column.name.etag=ETag
oss.file.info.label.hns.status=分层命名空间:
azure.column.name.access.tier=访问层级
file.info.access.tier=访问层级
file.info.access.tier.modified=访问层级上次修改时间
file.info.access.blob.type=Blob 类型
file.info.access.content.type=内容类型
error.object.summary.is.not.found=没有 {0} 的对象摘要
settings.buckets.user.list=帐户中的所有存储桶
settings.buckets.custom.list=自定义根
settings.buckets.hint=<html><b>帐户中的所有存储桶</b> - 执行某种 <it>list buckets</it> 请求。允许筛选结果存储桶列表。<br><br><b>自定义根</b> - 直接请求所选根，不仅允许指定存储桶，还允许指定目录的完整路径。</html>
custom.bucket.text.empty=bucket/folder,bucket2/folder/subfolder2,…
custom.bucket.text.hint=使用“,”分隔符指定源根列表 (bucket1/folder1/folder2,bucket2/folder)
gcs.multibucket.update.title=BigDataTools 的新 GCS 功能
gcs.multibucket.update.text=Google Cloud Storage 支持多存储桶! 您可以在连接设置中配置它们。
hdfs.column.name.group=组
hdfs.column.name.owner=所有者
hdfs.column.name.access.time=访问时间
hdfs.column.name.block.size=块大小
hdfs.column.name.permission=权限
hdfs.column.name.is.encrypted=已加密
hdfs.column.name.is.isSnapshotEnabled=快照
hdfs.column.name.is.isErasureCoded=已使用纠删码
hdfs.column.name.replications=副本
hdfs.file.info.label.group=组:
hdfs.file.info.label.owner=所有者:
hdfs.file.info.label.accessTime=访问时间:
hdfs.file.info.label.modificationTime=修改时间:
hdfs.file.info.label.block.size=块大小:
hdfs.file.info.label.replication=副本:
hdfs.file.info.label.permission=权限:
hdfs.file.info.label.isEncrypted=已加密:
hdfs.file.info.label.isSnapshotEnabled=已启用快照:
hdfs.file.info.label.isErasureCoded=已使用纠删码:
hdfs.file.info.label.size=大小:
emr.error.stop.cluster=停止集群错误
emr.connection.warning.no.clusters=已连接，找不到集群
emr.connection.warning.no.clusters.desc=已建立连接，但找不到所选区域的集群。请检查区域是否正确。
emr.connection.warning.no.clusters.desc.window=在“{0}”区域找不到集群。请检查区域。
emr.connection.creation=EMR 创建连接

bucket.name.is.empty.for.path=路径“{0}”的存储桶名称为空
auth.type.anon=匿名
connection.error.profile.config.file.is.not.found=通过路径 {0} 找不到配置文件
connection.error.profile.creds.file.is.not.found=通过路径 {0} 找不到凭据文件

java.wrong.path.inspection.description=在 Java 代码中高亮显示无效的 hdfs 路径
kotlin.wrong.path.inspection.description=在 Kotlin 代码中高亮显示无效的 hdfs 路径
scala.wrong.path.inspection.description=在 Scala 代码中高亮显示无效的 hdfs 路径
invalid.format.inspection.description=高亮显示自定义 hdfs 格式。默认情况下，预期格式为 parquet、orc、sequence、json、csv 或文本。
invalid.format.inspection.template=意外的自定义文件格式

# Inspections and highlightings
scala.serializable.scope.inspection.description=高亮显示在 spark 任务作用域内使用并且会导致运行时异常的不可序列化值。
scala.serializable.scope.inspection.warning=<html>Spark 作用域 {2} 中类型 {1} 的不可序列化值 {0}</html>

#Metainfo

metainfo.section.custom.headers=标头
emr.dialog.title.select.key.info.title=需要 SSH 密钥
emr.dialog.title.select.key.info.cancel=取消
emr.dialog.title.select.key.info.ok=选择 SSH 密钥
emr.dialog.title.select.key.info.msg=连接需要创建 SSH 隧道。要设置，请选择集群的 SSH 密钥文件。
settings.ssl.trust.all=信任所有 SSL 证书
metainfo.headers.key=键
metainfo.headers.value=值
metainfo.headers.empty=无自定义标头
alibaba.bucket.create.dialog.versioning=启用版本控制
settings.s3.region.group=AWS S3
settings.s3.region.group.label=区域:
settings.s3.region.group.china=AWS 中国
settings.s3.region.group.global=AWS 全球
settings.s3.region.group.us.gov=AWS GovCloud
connection.error.s3.auth.failed=访问密钥身份验证失败
connection.error.s3.access.key.is.not.found=找不到访问密钥
connection.error.s3.secret.key.is.not.found=找不到密钥
settings.properties=高级配置:
settings.generate.kerberos=Kerberos
kerberos.type.disabled=已禁用
kerberos.type.subject=JAAS 配置(专家)
kerberos.type.keytab=键表
connection.error.fs.and.user.not.found=找不到 URI {0} 和用户 {1} 的文件系统
settings.hdfs.kerberos.type=身份验证方式:
kerberos.type.credentials=密码
settings.kerberos.auth=身份验证:
settings.config.from.folder=解析的配置:
hdfs.property.source.explicit=自定义
hdfs.property.source.directory=配置文件夹
settings.validation.kerberos.keytab.error=必须指定键表和主体
settings.validation.kerberos.password.error=必须指定主体和密码
notification.group.orc.files=ORC 文件
inspection.scala.invalid.hdfs.file.path.display.name=高亮显示无效的 HDFS 文件路径
inspection.scala.custom.hdfs.format.display.name=高亮显示自定义 HDFS 文件格式
inspection.non.serializable.data.in.scope.display.name=高亮显示 Spark 任务中的不可序列化数据
inspection.kt.invalid.file.path.display.name=高亮显示无效的 HDFS 文件路径
inspection.kotlin.custom.hdfs.format.display.name=高亮显示自定义 HDFS 文件格式
inspection.java.invalid.file.path.display.name=高亮显示无效的 HDFS 文件路径
inspection.java.custom.hdfs.format.display.name=高亮显示自定义 HDFS 文件格式
settings.kerberos.auth.none=无
settings.kerberos.auth.kerberos=Kerberos
settings.hdfs.kinit=使用 kinit 缓存
settings.hdfs.username=Hadoop 用户名:
settings.hdfs.username.hint=登录服务器的用户名。如果未指定，则使用 <i>HAD00P_USER_NAME</i> 环境变量。如果未定义此变量，则使用 <i>user.name</i> 属性。如果启用了 Kerberos，它将重写这三个值。
gcs.sdk.update=Google Cloud SDK 已过时。<a>更新</a>
gcs.sdk.install=找不到 Google Cloud SDK。<a>安装</a>