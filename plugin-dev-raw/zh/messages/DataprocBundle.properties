
cluster.action.stop=終止集群…
cluster.details.not.found=找不到集群 {0} 的資訊。請重新整理 EMR 集群列表。
cluster.state.terminated.last.week=已於上周終止
cluster.state.terminated.last.day=已於前一天終止
cluster.state.terminated.last.hour=已於前一小時終止
cluster.state.terminated=已終止
cluster.state.running=有效
cluster.state.starting=正在啟動
metainfo.cluster.name=名稱:
metainfo.cluster.id=ID:
metainfo.cluster.status=狀態:
cluster.state.failed=已失敗
group.name.dataproc=GC Dataproc
emr.remove.linked.connections.title=Dataproc 連線
dataproc.toolwindow.title=GC Dataproc
cluster.info.summary.name=名稱:
cluster.info.summary.uiid=集群 UUID:
cluster.info.summary.type=類型:
cluster.info.summary.state=狀態:
cluster.info.summary.state.details=狀態詳細資訊:
cluster.info.config.region=區域:
cluster.info.config.zone=可用區
cluster.info.config.autoscaling=自動擴縮:
cluster.info.config.metastore=Dataproc 元存儲:
cluster.info.config.scheduled.deletion=定時刪除:
info.value.off=關閉
cluster.info.config.master.node.desc=主節點:
instance.config.machineType=機器類型:
instance.config.gpu.number=GPU 數量
instance.config.primary.disk.type=主磁碟類型:
instance.config.primary.disk.size=主磁碟大小:
instance.config.local.ssd=本地 SSD
cluster.info.config.worker.node.desc=工作程序節點:
cluster.info.config.secure.boot=安全啟動:
cluster.info.config.vtpm=VTPM:
cluster.info.config.monitoring=完整性監控:
cluster.info.config.bucket=Cloud Storage 暫存存儲分區:
cluster.info.config.network=網絡:
cluster.info.internal.ip=僅限內部 IP:
cluster.info.image.version=映像版本:
cluster.info.image.created=建立時間:
cluster.info.optional.components=可選組件:
cluster.info.properties=屬性:
cluster.info.labels=標籤:
cluster.tab.vb.instances.title=VM 實例
cluster.tab.jobs.title=作業
cluster.tab.info.title=資訊
cluster.tab.applications.title=應用程式
job.info.jobId=作業 ID:
job.info.jobUuid=作業 UUID:
job.info.status=狀態:
job.info.status.details=狀態詳細資訊:
job.info.start.date=開始日期:
job.info.elapsed.time=經過時間:
job.info.cluster=集群:
job.info.type=作業類型:
job.info.spark.args=實參:
job.info.labels=標籤
job.info.spark.main.class.or.jar=主類別或 jar
job.info.spark.jars=Jar:
job.info.spark.archives=歸檔:
job.info.spark.files=檔案:
job.info.spark.main.pyfile=主 Python 檔案:
job.info.spark.main.r.file=主 R 檔案:
job.info.query.file=查詢:
job.info.query.type=查詢源:
job.info.query.file.value=查詢檔案:
job.info.query.text.value=查詢文本:
job.info.properties=屬性
action.open.cluster.log=開啟 GC 日誌目錄
job.info.continue.on.failure=失敗時繼續
job.info.client.tags=客戶端標記
job.hadoop.title=Hadoop
job.spark.title=Spark
job.spark.r.title=SparkR
job.pyspark.title=PySpark
job.hive.title=Hive
job.spark.sql.title=SparkSql
job.pig.title=Pig
job.presto.title=Presto
add.job.title=提交作業
job.info.max.restart.per.hour=每小時最大重啟次數
job.properties.block.title=屬性
job.label.block.title=標籤
action.add.job.title=提交作業
job.info.spark.main.class.or.jar.title=主類別/檔案路徑
job.info.spark.jars.title=JAR
job.info.spark.archives.title=選擇歸檔
default.gcs.connection.name=GC Dataproc 專案
job.validation.file.fs={0} 必須為帶有 gs://、hdfs:// 或 file:// 前綴的檔案
job.validation.file.archive={0} 必須為歸檔類型 .jar、.tar、.tar.gz、.tgz、.zip。
job.info.spark.archives.hint=歸檔檔案已在 Spark 工作目錄中提取。可以是帶有 gs:// 前綴的 GCS 檔案、集群上帶有 hdfs:// 前綴的 HDFS 檔案或集群上帶有 file:// 前綴的本地檔案。支援的檔案類型包括: .jar、.tar、.tar.gz、.tgz、.zip。
job.info.spark.jars.hint=Jar 檔案包含在 CLASSPATH 中。可以是帶有 gs:// 前綴的 GCS 檔案、集群上帶有 hdfs:// 前綴的 HDFS 檔案或集群上帶有 file:// 前綴的本地檔案。
job.info.spark.main.class.or.jar.title.hint=提供的或標準 jar 檔案中類別的完全限定名稱(例如 com.example.wordcount)，或提供的 jar 檔案以使用該 jar 檔案的主類別
job.info.max.restart.per.hour.hint=如果您不想在作業失敗時自動重啟，請留空。
job.info.spark.main.r.file.title=選擇主 R 檔案
job.info.spark.additional.r.files.title=選擇附加 R 檔案
job.info.spark.additional.r.files=附加 R 檔案:
job.info.single.file.hint=可以是帶有 gs:// 前綴的 GCS 檔案、集群上帶有 hdfs:// 前綴的 HDFS 檔案或集群上帶有 file:// 前綴的本地檔案
job.info.spark.additional.py.files.title=選擇附加 Py 檔案
job.info.spark.additional.py.files=附加 Python 檔案:
job.info.spark.main.py.file.title=選擇主 Py 檔案
job.query.source.file=檔案
job.query.source.text=文本
job.query.source.type=查詢類型:
job.query.file.label=查詢檔案:
job.query.file.dialog.title=選擇查詢檔案:
job.query.text.label=查詢文本:
job.query.text.hint=要執行的查詢
auth.process.wait.authorization=GCloud 授權